<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Spectral Insights into Data-Oblivious Critical Layers
        in Large Language Models">
  <meta name="keywords" content="LLM, Critical Layers, Representation Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Spectral Insights into Data-Oblivious Critical Layers
        in Large Language Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/Pine.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <!-- MathJax for LaTeX rendering -->
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  </script>
</head>


<style>
  .AppE {
      color: #DAA520; /* myyellow */
      font-family: monospace;
      font-weight: bold;
  }
  .ShallowBlue {
      color: #267aba; /* mypurple */
      font-family: monospace;
      font-weight: bold;
  }
  .CollSgE {
      color: #ff570f; /* myorange */
      font-family: monospace;
      font-weight: bold;
  }
  .SAE {
      color: #003c73; /* mydarkblue */
      font-family: monospace;
      font-weight: bold;
  }
  .RepE {
      color: #00693e; /* mydarkblue */
      font-family: monospace;
      font-weight: bold;
  }
  .highlight {
      background-color: #F9CD69;
      font-weight: bold;
  }
  .CPLayer {
      color: #0f83ff; /* myorange */
      font-family: monospace;
      font-weight: bold;
  }
</style>

<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://xuyuan0204.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          
          <h1 class="title is-1 publication-title">Spectral Insights into Data-Oblivious Critical Layers
        in Large Language Models</h1>
          <div class="is-size-4 publication-authors">
            <span class="author-block">
              <a href="https://xuyuan0204.github.io/">Xuyuan Liu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://hsiung.cc/">Lei Hsiung</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/site/yangyaoqingcmu/">Yaoqing Yang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/umich.edu/yujunyan/home">Yujun Yan</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-4 publication-authors">
            <span class="author-block">
              <div style="text-align: center;">
                <div style="display: inline-block; position: relative;">
                  <img src="./static/images/D-Pine_RGB.png" alt="D-Pine Logo" style="max-width: 30px; height: auto; vertical-align: middle; margin-right: 0.1rem;">
                  <span style="position: relative;">
                    Dartmouth College<sup style="position: absolute; top: -0.5em; right: -0.5em;">1</sup>
                  </span>
                </div>
              </div>
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2506.00382"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/GraphmindDartmouth/Data-Oblivious-Critical-Layers"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/correlation_analysis_gradient.jpg" alt="Framework Correlation Visualization" style="max-width: 108%; height: auto;">
      <h2 class="subtitle has-text-centered">
        Spectral analysis reveals how LLMs will be trained in the next stage.
      </h2>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Understanding how feature representations evolve across layers in large language models (LLMs) is key to improving their interpretability and robustness. While recent studies have identified critical layers linked to specific functions or behaviors, these efforts typically rely on data-dependent analyses of fine-tuned models, limiting their use to post-hoc settings. In contrast, we introduce a \textit{data-oblivious} approach to identify intrinsic critical layers in pre-fine-tuned LLMs by analyzing representation dynamics via Centered Kernel Alignment (CKA). We show that layers with significant shifts in representation space are also those most affected during fine-tuningâ€”a pattern that holds consistently across tasks for a given model. Our spectral analysis further reveals that these shifts are driven by changes in the top principal components, which encode semantic transitions from rationales to conclusions.
We further apply these findings to two practical scenarios: efficient domain adaptation, where fine-tuning critical layers leads to greater loss reduction compared to non-critical layers; and backdoor defense, where freezing them reduces attack success rates by up to 40%.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Intro</h2>
          <p>
           LLMs are remarkably good at generating and understanding text, yet we still know little about how their internal layers process information. Previous work typically identifies "important" layers only after a model has been fine-tuned on a particular dataset, making these findings inherently post-hoc and dataset-specific. But are critical layers an intrinsic property of the model, independent of specific data? If so, can we predict a model's future training behavior from its current state alone?
          </p>
          
          <p>
            To investigate these questions, we adopt a different approach: we analyze off-the-shelf (pre-fine-tuned) models and show that <b>certain layers are intrinsically easier to adapt during subsequent fine-tuning</b>. We further demonstrate that each layer's <span class="RepE"><b>Representation Dynamics</b></span> reliably predicts its behavior in subsequent training steps, regardless of the dataset used.
          </p>
          


          <h2 class="title is-4">Data-oblivious Critical Layers & Representation Dynamics</h3>


          <h3 class="title is-5">Critical Layers Identified during Supervised Fine-Tuning.</h5>
          <p>
            We identify the critical layers during Supervised Fine-Tuning (SFT) by substituting each layer in the fine-tuned model with its corresponding layer from the pre-fine-tuned model, and then measure the loss reduction of the model during SFT for each layer. High values here indicates that the layer is more sensitive in the fine-tuning steps.
          </p>
          <div class="columns is-vcentered interpolation-panel" style="background: transparent;">
            <div class="column has-text-centered">
              <img src="./static/images/loss_visualization/llama7b_dolly_updated.png" alt="Loss Dolly Visualization" style="max-width: 100%; height: auto; background: transparent;">
              <div style="margin-top: 0.3em; font-size: 0.95em;"><em>Llama-2-7b's Loss reduction by layer on Dolly dataset</em></div>
            </div>
            <div class="column has-text-centered">
              <img src="./static/images/loss_visualization/llama7b_openbookqa_update.png" alt="Loss OpenBookQA Visualization" style="max-width: 100%; height: auto; background: transparent;">
              <div style="margin-top: 0.3em; font-size: 0.95em;"><em>Llama-2-7b's Loss reduction by layer on OpenBookQA dataset</em></div>
            </div>
          </div>
         

          <p>
            We find that the same model shows a <span style="color: #f11313;"><b>very similar pattern</b></span> in the loss curves across different datasets (high values in the middle layers, low values in the last layer), which indicates that the critical layer is determined by the pre-fine-tuned model and is independent of the fine-tuning dataset.
          </p>

          <h3 class="title is-5">Representation Dynamics of the Pre-fine-tuned Models</h4>
          <p>
            Centered Kernel Alignment (CKA) is a popular metric for measuring the similarity between two representation spaces. We use it to quantitatively describe changes in the representation space between layer $\ell$ and its neighboring layers, using the average CKA value, denoted as $\delta^{\ell}$. A smaller $\delta^{\ell}$ indicates a greater representation shift at layer $\ell$ relative to its neighbors. Layers with the largest shifts are called <span class="CPLayer">change-point layers</span>.
          </p>
          <div class="has-text-centered" style="margin-bottom: 0.2em;">
            <img src="./static/images/8b_boolq_cka.png" alt="8B BoolQ CKA Visualization" style="max-width: 80%; height: auto; display: block; margin-left: auto; margin-right: auto;" />
          </div>
          <div class="has-text-centered" style="margin-top: 0;">
            <img src="./static/images/8b_dolly_cka.png" alt="8B Dolly CKA Visualization" style="max-width: 80%; height: auto; display: block; margin-left: auto; margin-right: auto;" />
          </div>
          <div style="margin-top: 0.3em; font-size: 0.95em; text-align: center;"><em>Llama-3.1-8B's CKA similarity and average CKA $\delta^{\ell}$ by layer on BoolQ and Dolly datasets</em></div>
          <p>
            We also observe that these CKA patterns and the <span class="CPLayer">change-point layers</span> are independent of the data used to compute CKA, and are instead determined by the pre-fine-tuned model state.
          </p>

          <h3 class="title is-5">Connect Critical Layers with Representation Dynamics</h4>
          <p>
            From the figure above, we can also observe an interesting phenomenon that average CKA $\delta^{\ell}$ is negatively correlated with the tracked loss value after SFT. This trend is consistent with a high negative correlation coefficient across different models and datasets.         
          </p>

          <div class="has-text-centered" style="margin-top: 0;">
            <img src="./static/images/table2.jpg" alt="negative correlation table" style="max-width: 80%; height: auto; display: block; margin-left: auto; margin-right: auto;" />
          </div>
          <br>
          <div class="box" style="background-color: #e1dcdc; padding: 0.45em 0.6em; margin: 0.15em 0;">
            <div style="color: #003c73; font-weight: bold; font-size: 1.4em; text-align: center;">Take away</div>
            <div style="color: #222; font-weight: bold; font-style: italic; font-size: 1.1em; margin-top: 0.2em;">
              During the SFT stage, layers exhibiting greater shifts in representation space prior to fine-tuning tend to undergo more significant modifications compared to layers with minimal shifts.
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column">
            <div class="content">
              <h2 class="title is-4">Spectral Analysis of Representations</h3>
              <p>
                Having established that <span class="RepE"><b>Representation Dynamics</b></span> correlate with subsequent training behavior, and knowing that CKA is closely related to spectral properties, we investigate two key questions:
              </p>
    
              <ul>
                <li><strong>Q1: How do Principal Components explain the representation dynamics?</strong></li>
                <li><strong>Q2: What semantic information is encoded in the Principal Components?</strong></li>
              </ul>
    
              <h3 class="title is-5">Principal Components Explaining <span class="RepE"><b>Representation Dynamics</b></span></h4>
                <p>
                  We analyze how representation spaces evolve across layers by examining changes in their principal components using Canonical Correlation Analysis (CCA).
                </p>

                <div class="column has-text-centered">
                  <img src="./static/images/combined_res.png" alt="Top3 CCA Visualization" style="max-width: 100%; height: auto; background: transparent;">
                  <div style="margin-top: 0.3em; font-size: 0.95em;"><em>Average CCA values of the top-K principal components across layers in the LLaMA2-7B-Chat model on the Dolly dataset</em></div>
                </div>
                <p>
                  We observe a strong alignment between the average CCA values of the top-3 principal components and the average CKA patterns observed previously, especially at the <span class="CPLayer">change-point layers</span>. This indicates that the top-3 principal components are responsible for the representation shifts observed in the previous study.
                </p>




              <h3 class="title is-5">Semantic Information in Principal Components</h4>

              <p>
                We also investigate the semantic information encoded in the principal components by removing them at <span class="CPLayer">change-point layers</span> and observing how the model's output changes.
              </p>

              <div class="column has-text-centered">
                <img src="./static/images/CaseStudyExample.jpg" alt="Case Study Example" style="max-width: 100%; height: auto; background: transparent;">
                <div style="margin-top: 0.3em; font-size: 0.95em;"><em>The effects of removing different principal components at various layers</em></div>
              </div>
              <p>
                We find that the top-3 principal components at critical layers (which cause representation shifts) play a key role in summarizing rationales to derive conclusions during reasoning. In contrast, other principal components are primarily associated with formatting and template-related aspects.
              </p>
            </div>
          </div>
        </div>
      </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-4">Applications of Critical Layers</h3>
          <p>
            Finally, we present two key applications of identifying data-oblivious critical layers:
          </p>

          <h3 class="title is-5">Efficient Domain Adaptation</h4>
          <div class="content has-text-justified">
            <p>
              Critical layers can be leveraged for efficient domain adaptation when fine-tuning is restricted to a subset of layers due to resource constraints. We find that fine-tuning only the critical layers leads to faster loss decrease compared to fine-tuning non-critical layers.
            </p>
          </div>
          
          <div class="columns is-vcentered interpolation-panel" style="background: transparent;">
            <div class="column">
              <img src="./static/images/loss_dolly.jpg" alt="Loss Dolly Visualization" style="max-width: 100%; height: auto; background: transparent;">
            </div>
            <div class="column">
              <img src="./static/images/loss_openbookqa.jpg" alt="Loss OpenBookQA Visualization" style="max-width: 100%; height: auto; background: transparent;">
            </div>
          </div>
          
          <div style="margin-top: 0.3em; font-size: 0.95em; text-align: center;"><em>Test loss curves for fine-tuning LLaMA-2-7B-Chat on the Dolly and OpenBookQA datasets by training only the critical layers, only the non-critical layers, or the full model</em></div>


        <h3 class="title is-5">Targeted Defense Against Backdoor Attacks</h4>
        <div class="content has-text-justified">
          <p>
            Model robustness can be improved by preventing harmful information from adapting the critical layers. We find that freezing the critical layers leads to a significant reduction in attack success rates when the model faces backdoor attacks.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/attack_res.jpg" alt="Attack Results Visualization" style="max-width: 100%; height: auto;">
        </div>
           
        <p>
          Freezing the critical layers reduces attack success rates by up to 40%, and the defense also works against different triggers.
        </p>


        </div>
      </div>
    </div>
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{liu2025spectralinsightsdataobliviouscritical,
      title={Spectral Insights into Data-Oblivious Critical Layers in Large Language Models}, 
      author={Xuyuan Liu and Lei Hsiung and Yaoqing Yang and Yujun Yan},
      year={2025},
      eprint={2506.00382},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2506.00382}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
      <div class="columns is-centered">
          <div class="column is-8">
              <div class="content">
                  <p>
                      This website is borrowed from <a href="https://llm-tuning-safety.github.io/">LLM Finetuning
                          Risks</a>, <a href="https://nerfies.github.io/">Nerfies</a>,
                      <a href="https://hyunw.kim/fantom/">FANToM</a>,
                      and licensed under a <a rel="license"
                          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                          Commons Attribution-ShareAlike 4.0 International License</a>.
                  </p>
              </div>
          </div>
      </div>
  </div>
</footer>


</body>
</html>
